{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9vbhQUWRMtF",
        "outputId": "6348e911-9e0d-4d7e-a56c-efebe0558fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.6.1-py2.py3-none-any.whl (326 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/326.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/326.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.10.1)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->feature_engine) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature_engine) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.16.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.6.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install feature_engine\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PwXOwlPQ62O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
        "from feature_engine.encoding import OneHotEncoder\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKFEdpJ6Q_6A",
        "outputId": "6e5946cc-b0ee-4a85-ab55-e7f4f1be6233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqraHAybRBDt"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnUbyYNBRC_n"
      },
      "outputs": [],
      "source": [
        "#NEW DATA\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/데이콘/power_usage/new_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhiiCcNxREDo"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeycL6DFRF8x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from feature_engine.encoding import OneHotEncoder\n",
        "\n",
        "# Outlier 처리\n",
        "def remove_outliers(df):\n",
        "    cond = (df['강수량(mm)'] > 20) | (df['풍속(m/s)'] > 10)\n",
        "    return df.drop(df[cond].index)\n",
        "\n",
        "# 날짜 관련 처리\n",
        "def process_date(df):\n",
        "    df['주말'] = 0\n",
        "    df.loc[(df['일주일'] == 5) | (df['일주일'] == 6), '주말'] = 1\n",
        "    return df\n",
        "\n",
        "# 시간대 처리\n",
        "def bin_time(df):\n",
        "    df['시간_binned'] = df['시간'].apply(lambda x : '아침' if 0<x<8 else \"점심\" if 8 <= x < 18 else \"저녁\")\n",
        "    return df\n",
        "\n",
        "# 기온 관련 처리\n",
        "def process_temperature(df):\n",
        "    df['화씨기온(F)'] = (df['기온(C)'] * 9/5) + 32\n",
        "    df['이동평균기온'] = df['기온(C)'].rolling(window=24).mean()\n",
        "    return df\n",
        "\n",
        "# 기타 계산\n",
        "def calculate_extra_features(df):\n",
        "    df['기온_습도_interaction'] = df['기온(C)'] * df['습도(%)']\n",
        "    df['기온_풍속_interaction'] = df['기온(C)'] * df['풍속(m/s)']\n",
        "    df['기온_squared'] = df['기온(C)'] ** 2\n",
        "    df['습도_squared'] = df['습도(%)'] ** 2\n",
        "    df['기온_lag_1h'] = df['기온(C)'].shift(1)\n",
        "    return df\n",
        "\n",
        "# 결측치 처리\n",
        "def handle_missing_values(df):\n",
        "    df['강수량(mm)'].fillna(0, inplace=True)\n",
        "    df['풍속(m/s)'].fillna(df['풍속(m/s)'].median(), inplace=True)\n",
        "    df['습도(%)'].fillna(df['습도(%)'].median(), inplace=True)\n",
        "    df['태양광용량(kW)'].fillna(0, inplace=True)\n",
        "    df['ESS저장용량(kWh)'].fillna(0, inplace=True)\n",
        "    df['PCS용량(kW)'].fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# One Hot Encoding\n",
        "def one_hot_encoding(df):\n",
        "    df['건물번호'] = df['건물번호'].astype('object')\n",
        "    encoder = OneHotEncoder(variables=['건물유형','건물번호','시간_binned'])\n",
        "    return encoder.fit_transform(df)\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Datasets/데이콘/power_usage/new_df.csv\")\n",
        "\n",
        "    df = remove_outliers(df)\n",
        "    df = process_date(df)\n",
        "    df = bin_time(df)\n",
        "    df = process_temperature(df)\n",
        "    df = calculate_extra_features(df)\n",
        "    df = handle_missing_values(df)\n",
        "    df = df.drop(['일시'], 1)\n",
        "    df = one_hot_encoding(df)\n",
        "\n",
        "    return df\n",
        "    # 이후 작업\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = main()"
      ],
      "metadata": {
        "id": "VqokQsC9lOgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCo81VuoRJD1"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXjTN_wCRVuZ"
      },
      "outputs": [],
      "source": [
        "train = df[~df['전력소비량(kWh)'].isna()]\n",
        "test = df[df['전력소비량(kWh)'].isna()].drop(['전력소비량(kWh)'],1)\n",
        "\n",
        "X = train.drop(['전력소비량(kWh)'],1)\n",
        "y = train['전력소비량(kWh)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CYmdeD4RUf_",
        "outputId": "7c9452db-5a23-4f19-9e6a-459fcbcd71d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10 µs, sys: 0 ns, total: 10 µs\n",
            "Wall time: 12.6 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# SMAPE metriği\n",
        "def smape(y_true, y_pred):\n",
        "    return 1 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)) * 100)\n",
        "\n",
        "target = '전력소비량(kWh)'\n",
        "original_features = test.columns\n",
        "\n",
        "result_list = []\n",
        "def score_model(model, features_used, label=None):\n",
        "    score_list = []\n",
        "    oof = np.zeros_like(train[target])\n",
        "    tscv = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(tscv.split(train[original_features], train[target])):\n",
        "        X_train,X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train,y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        model = model\n",
        "        model.fit(X_train, y_train)\n",
        "        tscore = smape(y_train, model.predict(X_train))\n",
        "        y_test_pred = model.predict(X_test)\n",
        "        score = smape(y_test, y_test_pred)\n",
        "        print(f\" Fold {fold} : tscore = {tscore:.3f} score = {score:.3f}\")\n",
        "        oof[test_index] = y_test_pred\n",
        "        score_list.append(score)\n",
        "\n",
        "    score = sum(score_list) / len(score_list)\n",
        "    print(f\" Avg. smape score : {score:.3f}\")\n",
        "    if label is not None:\n",
        "        global result_list\n",
        "        result_list.append((label, score, oof))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaYRVTHCRt7j"
      },
      "source": [
        "# XGB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVECa8jfRxrl"
      },
      "source": [
        "## OPTUNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtoUG6fzRvHM"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    return 1 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)) * 100)\n",
        "\n",
        "def objective_xgb(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `XGBRegressor` model.\n",
        "    \"\"\"\n",
        "    tscv = TimeSeriesSplit(n_splits=10)\n",
        "    scores = []\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(tscv.split(train[original_features], train[target])):\n",
        "        X_train, X_test = train[original_features].iloc[train_index], train[original_features].iloc[test_index]\n",
        "        y_train, y_test = train[target].iloc[train_index], train[target].iloc[test_index]\n",
        "\n",
        "        params = {\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "            'gamma': trial.suggest_uniform('gamma', 0, 2),\n",
        "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 1.0),\n",
        "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "            'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
        "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-8, 0.1, log=True),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 2000, 3500),\n",
        "            'subsample': trial.suggest_loguniform('subsample', 0.05, 1),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        model = XGBRegressor(**params, tree_method='gpu_hist')\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        fold_smape = smape(y_test, pred)\n",
        "        scores.append(fold_smape)\n",
        "\n",
        "    return sum(scores) / len(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i50fRfbJRzTu"
      },
      "outputs": [],
      "source": [
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective_xgb, n_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzzvLAjmRhpX",
        "outputId": "d991b3d1-b4f5-41f3-9726-111ef8d1b99d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Fold 0 : tscore = 0.488 score = 43.242\n",
            " Fold 1 : tscore = 0.805 score = 60.814\n",
            " Fold 2 : tscore = 1.009 score = 64.335\n"
          ]
        }
      ],
      "source": [
        "xgb_params =  {'min_child_weight': 4, 'gamma': 0.3759792177779915, 'colsample_bytree': 0.7153976698720064, 'reg_alpha': 0.42305051144928957, 'reg_lambda': 1.1159900972673142, 'max_depth': 12, 'learning_rate': 0.014873233526991941,\n",
        "           'n_estimators': 3500, 'subsample': 0.4053585436167561}\n",
        "\n",
        "score_model(XGBRegressor(**xgb_params, tree_method='gpu_hist', random_state=42), features_used=test.columns, label=\"XGB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRPU3q5-R0-m"
      },
      "source": [
        "# LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoAb-GWTR1s5",
        "outputId": "e81773ed-021f-47f4-f8a7-f525eac4b4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Fold 0 : tscore = 3.062 score = 34.427\n",
            " Fold 1 : tscore = 3.843 score = 59.939\n",
            " Fold 2 : tscore = 4.094 score = 66.635\n",
            " Fold 3 : tscore = 3.764 score = 48.140\n",
            " Fold 4 : tscore = 4.650 score = 46.431\n",
            " Fold 5 : tscore = 4.883 score = 54.277\n",
            " Fold 6 : tscore = 4.874 score = 64.756\n",
            " Fold 7 : tscore = 5.149 score = 33.994\n",
            " Fold 8 : tscore = 5.327 score = 36.677\n",
            " Fold 9 : tscore = 5.652 score = 39.403\n",
            " Avg. smape score : 48.468\n"
          ]
        }
      ],
      "source": [
        "score_model(LGBMRegressor(n_estimators = 1000, random_state=42, verbose=-1, learning_rate=0.099), features_used=test.columns, label=\"LGBM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otmye8O6Xvd8"
      },
      "source": [
        "## OPTUNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34qMtB82XjMD"
      },
      "outputs": [],
      "source": [
        "def smape(y_true, y_pred):\n",
        "    return 1 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)) * 100)\n",
        "\n",
        "def objective_lgbm(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `XGBRegressor` model.\n",
        "    \"\"\"\n",
        "    tscv = TimeSeriesSplit(n_splits=10)\n",
        "    scores = []\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(tscv.split(train[original_features], train[target])):\n",
        "        X_train, X_test = train[original_features].iloc[train_index], train[original_features].iloc[test_index]\n",
        "        y_train, y_test = train[target].iloc[train_index], train[target].iloc[test_index]\n",
        "\n",
        "        params = {\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
        "            'gamma': trial.suggest_uniform('gamma', 0, 2),\n",
        "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 1.0),\n",
        "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "            'max_depth': trial.suggest_int('max_depth', 8, 25),\n",
        "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-8, 0.1, log=True),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 200, 4000),\n",
        "            'subsample': trial.suggest_loguniform('subsample', 0.05, 1),\n",
        "        }\n",
        "\n",
        "        model = LGBMRegressor(**params,random_state=42, verbose=-1)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        fold_smape = smape(y_test, pred)\n",
        "        scores.append(fold_smape)\n",
        "\n",
        "    return sum(scores) / len(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaOUUevoSMuA"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective_lgbm, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQwkCeLAhN_Z"
      },
      "outputs": [],
      "source": [
        "lgbm_params = {'min_child_weight': 1, 'gamma': 1.3655561121466593, 'colsample_bytree': 0.91218315174515, 'reg_alpha': 0.5629425361195333, 'reg_lambda': 5.727596183557824, 'max_depth': -1, 'learning_rate': 0.048484317534138836, 'n_estimators': 3000, 'subsample': 0.352325899422433}\n",
        "score_model(LGBMRegressor(random_state=42, **lgbm_params, verbose=-1), features_used=test.columns, label=\"LGBM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjRqAqZNSG-r"
      },
      "source": [
        "# FINAL MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hMgQetkp7He"
      },
      "source": [
        "# Single model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OK71waCJSHwT",
        "outputId": "8610077b-6991-40ea-8c0d-8f7f13099de0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.7153976698720064, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=0.3759792177779915, gpu_id=None, grow_policy=None,\n",
              "             importance_type=None, interaction_constraints=None,\n",
              "             learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "             max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
              "             max_leaves=None, min_child_weight=4, missing=nan,\n",
              "             monotone_constraints=None, n_estimators=3700, n_jobs=None,\n",
              "             num_parallel_tree=None, predictor=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.7153976698720064, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=0.3759792177779915, gpu_id=None, grow_policy=None,\n",
              "             importance_type=None, interaction_constraints=None,\n",
              "             learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "             max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
              "             max_leaves=None, min_child_weight=4, missing=nan,\n",
              "             monotone_constraints=None, n_estimators=3700, n_jobs=None,\n",
              "             num_parallel_tree=None, predictor=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.7153976698720064, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=0.3759792177779915, gpu_id=None, grow_policy=None,\n",
              "             importance_type=None, interaction_constraints=None,\n",
              "             learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "             max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
              "             max_leaves=None, min_child_weight=4, missing=nan,\n",
              "             monotone_constraints=None, n_estimators=3700, n_jobs=None,\n",
              "             num_parallel_tree=None, predictor=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model1 = XGBRegressor(random_state=42,tree_method='gpu_hist', **xgb_params)\n",
        "model1.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "kYaQogqkySJH",
        "outputId": "8ab3d73c-1079-4cd3-e526-7393a8fe9ca5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(colsample_bytree=0.91218315174515, gamma=1.3655561121466593,\n",
              "              learning_rate=0.048484317534138836, min_child_weight=1,\n",
              "              n_estimators=3500, random_state=42, reg_alpha=0.5629425361195333,\n",
              "              reg_lambda=5.727596183557824, subsample=0.352325899422433,\n",
              "              verbose=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.91218315174515, gamma=1.3655561121466593,\n",
              "              learning_rate=0.048484317534138836, min_child_weight=1,\n",
              "              n_estimators=3500, random_state=42, reg_alpha=0.5629425361195333,\n",
              "              reg_lambda=5.727596183557824, subsample=0.352325899422433,\n",
              "              verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.91218315174515, gamma=1.3655561121466593,\n",
              "              learning_rate=0.048484317534138836, min_child_weight=1,\n",
              "              n_estimators=3500, random_state=42, reg_alpha=0.5629425361195333,\n",
              "              reg_lambda=5.727596183557824, subsample=0.352325899422433,\n",
              "              verbose=-1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model2 = LGBMRegressor(**lgbm_params, random_state=42, verbose=-1)\n",
        "model2.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS1XStkjp9Bd"
      },
      "source": [
        "## VOTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTdoH9YSp-oq"
      },
      "outputs": [],
      "source": [
        "vot_model = VotingRegressor(estimators=[\n",
        "    ('xgb',model1),\n",
        "    ('lgbm',model2),\n",
        "])\n",
        "\n",
        "model = vot_model.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82U_pt5CSKby",
        "outputId": "54863b8d-cd9f-4506-ec4d-831b151066d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100.166260    2\n",
              "859.477051     2\n",
              "2080.144775    2\n",
              "1441.541016    2\n",
              "1553.209595    1\n",
              "              ..\n",
              "3171.648682    1\n",
              "3181.994629    1\n",
              "3172.928223    1\n",
              "3173.538330    1\n",
              "568.382874     1\n",
              "Name: answer, Length: 16796, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dir = \"/content/drive/MyDrive/Datasets/데이콘/power_usage/open\"\n",
        "ss = pd.read_csv(dir + \"/sample_submission.csv\")\n",
        "ss['answer'] = model1.predict(test)\n",
        "ss['answer'] = ss['answer'].clip(0,)\n",
        "ss['answer'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCxT0fENSLZY"
      },
      "outputs": [],
      "source": [
        "ss.to_csv(\"./xgb_lgbm_xgb_maxdepth_12_xgb_esti_3700_lr_lgbm_esti_3500.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}