{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fc3f4f",
   "metadata": {},
   "source": [
    "# Contest Objetive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90e815",
   "metadata": {},
   "source": [
    "치과 구강이미지 합성 데이터 분양의 헬스케어 AI 경진대회이며, 구강이미지 내 충치 유무 판별 모델 개발을 목표로 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164629c6",
   "metadata": {},
   "source": [
    "# Competition Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676e5b8",
   "metadata": {},
   "source": [
    "- 참 가  신 청 : 2023년 11월 30일(금) ~ 12월 05(화)\n",
    "- 대 회  참 가 : 2023년 12월 11일(월) ~ 12월 15(금) 18:00 까지\n",
    "- 레포트 제출 : 2023년 12월 17일(일) 낮 12:00 까지\n",
    "- 심 사  기 간 : 2023년 12월 17일(일)\n",
    "- 결 과  발 표 : 2023년 12월 18일(월) \n",
    "- 시    상   식 : ’23.12.21.(목)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2212f",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db698d8",
   "metadata": {},
   "source": [
    "1. 본 경진대회는 동일한 환경(ssh & vim editor)과 동일한 GPU를 참가자에게 분배함.\n",
    "2. 주최측에서 Resnet기반 모델 사용을 권장하였으며, `resnet50_binary` 모델 사용\n",
    "3. 일부 참가자의 GPU 독점 이슈로, 배치 사이즈(12) 및 에폭 수(6)를 낮게 설정함.\n",
    "4. 손실함수는 CrossEntropy, 옵티마이저는 Adam(lr=0.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1186b0",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33d8d7",
   "metadata": {},
   "source": [
    "- 충치가 하나라도 있으면 True로 출력하는 Resnet기반 모델을 개발함.\n",
    "- GPU 이슈로 light한 `Resnet50_binary` 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Tuple\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion_factor = 1\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion_factor * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion_factor * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion_factor * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: nn.Module, num_blocks: List[int], num_classes: int = 1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.conv2 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.conv3 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.conv4 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.conv5 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion_factor, num_classes)\n",
    "\n",
    "        self._init_layer()\n",
    "\n",
    "    def _make_layer(self, block: nn.Module, out_channels: int, num_blocks: int, stride: int):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion_factor\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_layer(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.sigmoid(self.fc(x))  # Apply sigmoid activation for binary classification\n",
    "        return x\n",
    "\n",
    "# ResNet-18\n",
    "def resnet18_binary(num_classes: int = 2) -> ResNet:\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
    "\n",
    "# ResNet-34\n",
    "def resnet34_binary(num_classes: int = 2) -> ResNet:\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "# ResNet-50\n",
    "def resnet50_binary(num_classes: int = 2) -> ResNet:\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "# ResNet-101\n",
    "def resnet101_binary(num_classes: int = 2) -> ResNet:\n",
    "    return ResNet(BasicBlock, [3, 4, 23, 3], num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e2e94",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c03e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "from resnet import resnet18_binary, resnet34_binary, resnet50_binary, resnet101_binary\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "#arguments 지정\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='Tooth Decay Model Training')\n",
    "    parser.add_argument('--num_epochs', type=int, default=100, help='에폭 설정')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='lr 설정')\n",
    "    parser.add_argument('--image_dir', type=str, default='/qorskawls12/Dataset/train_data/image/', help='이미지 경로')\n",
    "    parser.add_argument('--json_dir', type=str, default='/qorskawls12/Dataset/train_data/json/', help='json 경로')\n",
    "    parser.add_argument('--model_dir', type=str, default='/qorskawls12/model_1216/', help='pt파일 저장 경로')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='배치 사이즈')\n",
    "    parser.add_argument('--epoch_interval', type=int, default=1, help='모델 저장 간격 (에폭)')\n",
    "    parser.add_argument('--pretrained_model_path', type=str, default='/qorskawls12/model_1215/resnet_lr0.001_ep6_bs12.pt', help='미리 학습된 모델 경로')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main(args):\n",
    "    # 변경 전처리 추가\n",
    "    data_transform = A.Compose([\n",
    "        A.Resize(900, 1500),\n",
    "        A.Rotate(limit=20, p=0.3),\n",
    "        A.CLAHE(clip_limit=3.0, tile_grid_size=(8, 8), p=0.4),\n",
    "        A.RandomBrightnessContrast(p=0.4, brightness_limit=-0.3, contrast_limit=-0.3)\n",
    "    ])\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        def pil_to_numpy(self,image):\n",
    "            return np.array(image)\n",
    "\n",
    "        def __init__(self, image_dir, json_dir, transform=None):\n",
    "            self.image_dir = image_dir\n",
    "            self.json_dir = json_dir\n",
    "            self.transform = transform\n",
    "\n",
    "            self.samples = []\n",
    "            for image_file in os.listdir(image_dir):\n",
    "                if image_file.endswith('.png'):\n",
    "                    image_path = os.path.join(image_dir, image_file)\n",
    "                    json_path = os.path.join(json_dir, image_file.replace('.png', '.json'))\n",
    "                    self.samples.append((image_path, json_path))\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image_path, json_path = self.samples[idx]\n",
    "\n",
    "            # 이미지 로드\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image_np = self.pil_to_numpy(image)\n",
    "\n",
    "            if self.transform:\n",
    "                transformed = self.transform(image=image_np)\n",
    "                image = transformed['image']\n",
    "\n",
    "            # JSON 파일 로드\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                decayed_values = [tooth[\"decayed\"] for tooth in json_data['tooth']]\n",
    "\n",
    "            # 라벨 설정\n",
    "            label = torch.tensor(int(any(decayed_values)), dtype=torch.float32)\n",
    "            labels = label.type(torch.LongTensor)\n",
    "            return image, labels\n",
    "\n",
    "    # 데이터셋 및 데이터로더 생성\n",
    "    dataset = CustomDataset(args.image_dir, args.json_dir, transform=data_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=  args.batch_size , shuffle=True)\n",
    "\n",
    "    # GPU 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    ## pretrain 모델 정의\n",
    "    pretrain_model = resnet50_binary()\n",
    "    pretrain_model.load_state_dict(torch.load(args.pretrained_model_path))\n",
    "    pretrain_model.to(device)\n",
    "\n",
    "    # 현재 모델 정의\n",
    "    model = resnet50_binary().to(device)\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "\n",
    "    # 미리 학습된 가중치 적용\n",
    "    model.load_state_dict(pretrain_model.state_dict(), strict=False)\n",
    "\n",
    "    # 손실 함수 및 옵티마이저 정의\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # 학습\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for batch_index, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            print(f\"Processing Batch {batch_index+1}/{len(dataloader)}\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{args.num_epochs}, Loss: {loss.item()}')\n",
    "        # 지정한 간격만큼 중간 모델 저장\n",
    "        if (epoch + 1) % args.epoch_interval == 0:\n",
    "            model_path = os.path.join(args.model_dir, f'{model_name}_ep{epoch+1}_bs{args.batch_size}.pt')\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f'[~ing] SUCCESS! Saved to {model_path} (Epoch {epoch+1})')\n",
    "    # 학습된 모델 저장\n",
    "    model_path = os.path.join(args.model_dir, f'final_{model_name}_l_ep{args.num_epochs}_train.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f'[finish] SUCCESS! Saved to {model_path}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arguments = parse_arguments()\n",
    "    main(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169aab56",
   "metadata": {},
   "source": [
    "# Learning & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5922c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from resnet import resnet50_binary\n",
    "from sklearn.metrics import f1_score\n",
    "import argparse\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Load Model\n",
    "def load_model(model_path, model_class, num_classes=2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = \"cpu\"\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "#Learning & Evaluation\n",
    "def perform_inference_and_evaluate(model, test_json_dir, image_path, transform, threshold, true_labels, predicted_labels):\n",
    "    device = next(model.parameters()).device\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    image_filename = os.path.basename(image_path)\n",
    "    new_json_path = os.path.join(test_json_dir, image_filename.replace('.png', '.json'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    #probability = torch.sigmoid(output).item()\n",
    "    #prediction = probability > threshol\n",
    "    # 소프트맥스 함수를 사용하여 확률 계산\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "\n",
    "    # 가장 높은 확률을 가진 클래스 선택\n",
    "    _, prediction_class = torch.max(probabilities, 1)\n",
    "\n",
    "    # 예측값과 실제값 추가\n",
    "    predicted_labels.append(bool(prediction_class.item()))\n",
    "\n",
    "    # 실제값 추출\n",
    "    with open(new_json_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        true_decayed_values = [tooth[\"decayed\"] for tooth in json_data['tooth']]\n",
    "        true_label = torch.tensor(int(any(true_decayed_values)), dtype=torch.float32)\n",
    "        true_labels.append(int(true_label))\n",
    "\n",
    "    return (bool(prediction_class.item())), true_label\n",
    "def create_predictions_list_and_evaluate(model, test_json_dir, image_dir, transform, threshold):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for index, image_file in enumerate(os.listdir(image_dir)):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            pred_label, true_label = perform_inference_and_evaluate(model, test_json_dir, image_path, transform, threshold, true_labels, predicted_labels)\n",
    "\n",
    "            #predictions.append({\n",
    "            #    \"image_file\": image_file,\n",
    "            #    \"decayed\": prediction\n",
    "            #})\n",
    "            predictions.append(int(pred_label))\n",
    "\n",
    "            print(f\"Index: {index}/{len(os.listdir(image_dir))}, true label: {int(true_label)}, pred_label:{int(pred_label)}\")\n",
    "\n",
    "    return predictions, true_labels, predicted_labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"start!\")\n",
    "    parser = argparse.ArgumentParser(description='Tooth Decay Model Inferencne')\n",
    "    parser.add_argument('--model_path', type=str, required=True, help='모델 파일(.pt) 경로')\n",
    "    parser.add_argument('--threshold', type=float, default=0.5, help='임계값')\n",
    "    parser.add_argument('--output_json_dir', type=str, default='/qorskawls12/predict/', help='JSON 파일 결과를 저장할 디렉토리')\n",
    "    parser.add_argument('--test_image_dir', type=str, default='/qorskawls12/Dataset/test_data/image/', help='testdata/image/* 경로')\n",
    "    parser.add_argument('--test_json_dir', type=str, default='/qorskawls12/Dataset/test_data/json/', help='testdata/json/* 경로')\n",
    "    parser.add_argument('--output_txt_dir', type=str, default='/qorskawls12/output_txt/', help='텍스트 파일 경로')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Inference start\")\n",
    "    # 모델 로드\n",
    "    model = load_model(args.model_path, resnet50_binary)\n",
    "\n",
    "    # 변환 정의\n",
    "    inference_transform = transforms.Compose([\n",
    "        transforms.Resize((900, 1500)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # 인퍼런스 결과 리스트 및 F1 Score 계산\n",
    "    predictions, true_labels, predicted_labels = create_predictions_list_and_evaluate(\n",
    "        model, args.test_json_dir, args.test_image_dir, inference_transform, args.threshold\n",
    "    )\n",
    "\n",
    "    # 결과를 JSON으로 저장\n",
    "    model_filename = os.path.basename(args.model_path)\n",
    "    json_filename = os.path.splitext(model_filename)[0] + '_predictions.json'\n",
    "    output_json_path = os.path.join(args.output_json_dir, json_filename)\n",
    "\n",
    "    with open(output_json_path, 'w') as json_file:\n",
    "        json.dump({\"predict\": predictions}, json_file, indent=2)\n",
    "\n",
    "    precision, recall, f1_score ,_ = precision_recall_fscore_support(true_labels, predicted_labels,labels=[1], average='binary')\n",
    "\n",
    "    print(f'Precision for class 1 (decayed 양성)): {precision[0]:.2f}')\n",
    "    print(f'Recall for class 1 (decayed 양성): {recall[0]:.2f}')\n",
    "    print(f'F1 Score for class 1 (decayed 양성): {f1_score[0]:.2f}')\n",
    "\n",
    "    ## 최종 결과를 저장할 output_txt 파일 명 : 모델 pt파일을 따서 네이밍\n",
    "    output_txt_path = os.path.join(args.output_txt_dir, os.path.splitext(model_filename)[0] + '_output.txt')\n",
    "    with open(output_txt_path, 'w') as txt_file:\n",
    "        txt_file.write(f'Precision for class 1 (decayed 양성)): {precision[0]:.2f}\\n')\n",
    "        txt_file.write(f'Recall for class 1 (decayed 양성): {recall[0]:.2f}\\n')\n",
    "        txt_file.write(f'F1 Score for class 1 (decayed 양성): {f1_score[0]:.2f}\\n')\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time) / 60\n",
    "        print(f\"Finish inference & f1-score(성능 : {f1_score[0]:.2f})! \\n 걸린 시간 : {elapsed_time:.2f} 분\")\n",
    "        txt_file.write(f\"Finish inference & f1-score(성능 : {f1_score[0]:.2f})! \\n 걸린 시간 : {elapsed_time:.2f} 분\\n\")        txt_file.write(f\"\\n\\n\\n--------------예측값과 실제값 레이블 출력 결과----------------\\n\\n\\n\")\n",
    "        for index, (true_label, pred_label) in enumerate(zip(true_labels, predicted_labels)):\n",
    "            txt_file.write(f\"Index: {index}, true label: {true_label}, pred_label: {int(pred_label)}\\n\")                                                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d68211",
   "metadata": {},
   "source": [
    "* Precision for class 1 (decayed 양성)): 1.0000\n",
    "* Recall for class 1 (decayed 양성): 0.9990\n",
    "* F1 Score for class 1 (decayed 양성): 0.9995\n",
    "* Finish inference & f1-score(성능 : 0.9995)!\n",
    "    - 걸린 시간 : 6.51 분"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
